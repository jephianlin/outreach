{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 我們與數字辨識的距離\n",
    "林晉宏 (Jephian Lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "此投影片由 Jupyter 製作  \n",
    "原始檔請見下方連結  \n",
    "https://github.com/jephianlin/outreach/blob/master/NSYSU-digits/NSYSU-digits.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- [MNIST 手寫數字資料庫](#MNIST-database)\n",
    "- [NSYSU-digits 手寫數字資料集](#NSYSU-digits-dataset)\n",
    "- [資料前處理](#Data-processing)\n",
    "- [專案中遇到的困難、犯過的錯誤](#Difficulties/Mistakes-in-the-NSYSU-digits-project)\n",
    "- [總結](#Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load, dump\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### load MNIST\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "Xf_train = X_train.reshape(60000, -1)\n",
    "Xf_test = X_test.reshape(10000, -1)\n",
    "Xcnn_train = X_train.reshape(60000, 28, 28, 1)\n",
    "Xcnn_test = X_test.reshape(10000, 28, 28, 1)\n",
    "yone_train = tf.keras.utils.to_categorical(y_train)\n",
    "yone_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### load nsysu\n",
    "\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "base = r\"https://github.com/SageLabTW/auto-grading/raw/master/nsysu-digits/\"\n",
    "for c in ['X', 'y']:\n",
    "    filename = \"nsysu-digits-%s.csv\"%c\n",
    "    if filename not in os.listdir('.'):\n",
    "        print(filename, 'not found --- will download')\n",
    "        urllib.request.urlretrieve(base + c + \".csv\", filename)\n",
    "\n",
    "Xsys = np.genfromtxt('nsysu-digits-X.csv', dtype=int, delimiter=',') ### flattened already\n",
    "ysys = np.genfromtxt('nsysu-digits-y.csv', dtype=int, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### adjust data format\n",
    "\n",
    "num = Xsys.shape[0] ### 552\n",
    "Xsyscnn = Xsys.reshape(num, 28, 28, 1)\n",
    "ysysone = tf.keras.utils.to_categorical(ysys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MNIST database\n",
    "MNIST 手寫數字資料庫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[back to top](#%E6%88%91%E5%80%91%E8%88%87%E6%95%B8%E5%AD%97%E8%BE%A8%E8%AD%98%E7%9A%84%E8%B7%9D%E9%9B%A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Webpage of MNIST dataset](MNIST-webpage.png \"Webpage of MNIST dataset\")\n",
    "\n",
    "http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 資料集內容\n",
    "- 訓練集：60,000 張圖片\n",
    "- 測試集：10,000 張圖片\n",
    "- 以 `idx` 格式儲存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![MNIST examples](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png \"MNIST examples\")\n",
    "\n",
    "(Source: [Wikipedia of MNIST database](https://en.wikipedia.org/wiki/MNIST_database)  \n",
    "author: Josef Steppan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 資料來源\n",
    "- 取自 [NIST](https://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology) 中的兩個資料集\n",
    "- Special Database 3：公務員寫的\n",
    "- Special Database 1：中學生寫的\n",
    "- MNIST training = 30,000 SD3 + 30,000 SD1\n",
    "- MNIST testing = 1,000 SD3 + 1,000 SD1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "原先 NIST 把 SD3 當訓練集  \n",
    "把 SD1 當測試集  \n",
    "由於兩邊手寫作者身份差太多  \n",
    "MNIST 將兩資料集重新混合\n",
    "\n",
    "Census Bureau 的公務員"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 資料前處理\n",
    "- 每張圖大小為 28x28\n",
    "- 數字部份包在 20x20 的方框中\n",
    "- 白 0 ~ 255 黑\n",
    "- 依顏料重心置中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### check shape, bounding box, and mass center\n",
    "i = 0\n",
    "arr = X_train[i]\n",
    "print(\"image shape is\", arr.shape)\n",
    "ink_x,ink_y = np.where(arr > 0)\n",
    "print(\"vertical ink range is\", ink_x.min(), \"~\", ink_x.max())\n",
    "print(\"horizontal ink range is\", ink_y.min(), \"~\", ink_y.max())\n",
    "row_sum = np.sum(arr, axis=1)\n",
    "print(\"vertical mass center at\", (row_sum * np.arange(28)).sum() / row_sum.sum()) # ~ 13.5\n",
    "col_sum = np.sum(arr, axis=0)\n",
    "print(\"horizontal mass center at\", (col_sum * np.arange(28)).sum() / col_sum.sum()) # ~ 13.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Records for models](MNIST-models.png \"Records for models\")\n",
    "\n",
    "http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 沒辦法中的辦法\n",
    "- 亂猜 ~10%\n",
    "- 看墨水用量 ~ 22%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "各數字的墨水用量分佈  \n",
    "![Distribution of ink densities](ink-density.png \"Distribution of ink densities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "用墨水猜測的答對率（confusion matrix）\n",
    "\n",
    "![Confusion matrix of ink estimator](ink-confusion-matrix.png \"Confusion matrix of ink estimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### random guess\n",
    "guess = np.random.randint(0, 10, (10000,))\n",
    "accuracy_score(y_test, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### ink density histogram\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "for i in range(10):\n",
    "    mask = (y_train == i)\n",
    "    wanted = X_train.reshape(60000, -1)[mask].mean(axis=1)\n",
    "    plt.hist(wanted, bins=100, label='%s'%i)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### ink density guess\n",
    "centers = np.zeros((10,1))\n",
    "label = np.arange(10)\n",
    "for i in range(10):\n",
    "    mask = (y_train == i)\n",
    "    centers[i,0] = X_train[mask].mean()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(1)\n",
    "model.fit(centers, label)\n",
    "inks = X_test.reshape(10000,-1).mean(axis=1)[:,np.newaxis]\n",
    "guess = model.predict(inks)\n",
    "accuracy_score(y_test, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### confusion matrix\n",
    "### need to run the previous cell first\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = plt.gca()\n",
    "plot_confusion_matrix(model, inks, y_test, normalize='true', values_format='.2f', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 將圖片拉平\n",
    "\n",
    "```python\n",
    "a = np.array([[1,2],\n",
    "              [2,3]])\n",
    "a.reshape(-1)\n",
    "```\n",
    "會得到  \n",
    "```\n",
    "[1,2,2,3]\n",
    "```\n",
    "每個圖片都可以看成是 28x28 = 784 維的向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 距離\n",
    "若 $x = (x_1, \\ldots, x_n)$,  \n",
    "$y = (y_1, \\ldots, y_n)$  \n",
    "\n",
    "則兩點之間距離為  \n",
    "$\\|x-y\\| = \\sqrt{\\sum_{i=1}^n (x_i - y_i)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### k-nearest neighbors\n",
    "96.8% ~ 99.37%  \n",
    "(10 minutes on i7-8700 12 cores)\n",
    "\n",
    "![k-nearest neighbors](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/220px-KnnClassification.svg.png \"k-nearest neighbors\")\n",
    "\n",
    "(Source: [Wikipedia of k-nearest neighbors algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)  \n",
    "author: Antti Ajanki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(Xf_train, y_train)\n",
    "guess = model.predict(Xf_test)\n",
    "accuracy_score(y_test, guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Linear classifier\n",
    "88% ~ 92.4%\n",
    "\n",
    "![Linear classifier](https://raw.githubusercontent.com/jephianlin/ModularPython/master/linear_classifier.png \"Linear classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### linear\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(hidden_layer_sizes=(), activation='identity')\n",
    "model.fit(Xf_train, y_train)\n",
    "guess = model.predict(Xf_test)\n",
    "accuracy_score(y_test, guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Support vector machine\n",
    "97.9% ~ 99.44%\n",
    "(7 minutes on i7-8700 12 cores)\n",
    "\n",
    "![Kernel function](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/500px-Kernel_Machine.svg.png \"Kernel function\")\n",
    "\n",
    "(Source: [Wikipedia of Support vector machine](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)  \n",
    "author: Alisneaky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### SVM\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(Xf_train, y_train)\n",
    "guess = model.predict(Xf_test)\n",
    "accuracy_score(y_test, guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Neural network\n",
    "92% ~ 99.17%\n",
    "\n",
    "- 每層神經網路 = 一個矩陣 $W$、一個向量 $b$、一個非線性函數 $\\sigma$\n",
    "- 輸入 $x$ 和輸出 $y$ 的關係  \n",
    "$y = \\sigma(xW +b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### neural network\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(Xf_train, yone_train, epochs=10, batch_size=100, validation_data=(Xf_test, yone_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 距離？\n",
    "算一下 $x$, $y$, $z$ 之間的距離：\n",
    "```python\n",
    "x = [0,1,0,0,1,0,0,1,0]\n",
    "y = [0,0,1,0,0,1,0,0,1]\n",
    "z = [1,1,1,1,0,1,1,1,1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Distance between pictures](xyz-distance.png \"Distance between pictures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### draw xyz-distance.png\n",
    "x = np.array([0,1,0,0,1,0,0,1,0]).reshape(3,3)\n",
    "y = np.array([0,0,1,0,0,1,0,0,1]).reshape(3,3)\n",
    "z = np.array([1,1,1,1,0,1,1,1,1]).reshape(3,3)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "back = fig.add_axes([0,0,1,1])\n",
    "ax1 = fig.add_axes([0.1,0.2,0.2,0.2])\n",
    "ax1.imshow(x, cmap='Greys')\n",
    "ax2 = fig.add_axes([0.7,0.2,0.2,0.2])\n",
    "ax2.imshow(y, cmap='Greys')\n",
    "ax3 = fig.add_axes([0.4,0.7,0.2,0.2])\n",
    "ax3.imshow(z, cmap='Greys')\n",
    "back.text(0.3, 0.5, '$\\sqrt{7}$', size='xx-large', usetex=True, ha='center')\n",
    "back.text(0.7, 0.5, '$\\sqrt{5}$', size='xx-large', usetex=True, ha='center')\n",
    "back.text(0.5, 0.3, '$\\sqrt{6}$', size='xx-large', usetex=True, ha='center')\n",
    "\n",
    "back.set_axis_off()\n",
    "for ax in [ax1, ax2, ax3]:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Convolution\n",
    "![Convolution](convolution.png \"Convolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### draw convolution.png\n",
    "arr = np.abs(X_train[1][:,2:] - X_train[1][:,:-2])\n",
    "fea,vis = hog(X_train[1], pixels_per_cell=(4,4), cells_per_block=(2,2), visualize=True)\n",
    "\n",
    "fig = plt.figure(figsize=(9,3))\n",
    "axs = fig.subplots(1,3)\n",
    "axs[0].imshow(X_train[1], cmap='Greys')\n",
    "axs[0].set_title('original')\n",
    "axs[1].imshow(arr, cmap='Greys')\n",
    "axs[1].set_title('[-1,0,1] filter')\n",
    "axs[2].imshow(vis, cmap='Greys')\n",
    "axs[2].set_title('HOG feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Convolution neural network\n",
    "97% ~ 99.77%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### convolution neural network\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), \n",
    "                                 activation='relu', \n",
    "                                 input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(Xcnn_train, yone_train, epochs=1, batch_size=100, validation_data=(Xcnn_test, yone_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NSYSU-digits dataset\n",
    "NSYSU-digits 手寫數字資料集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[back to top](#%E6%88%91%E5%80%91%E8%88%87%E6%95%B8%E5%AD%97%E8%BE%A8%E8%AD%98%E7%9A%84%E8%B7%9D%E9%9B%A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 資料集內容\n",
    "- 共 552 張圖片\n",
    "- 未區分訓練集及測試集\n",
    "- 以 `png` 格式儲存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![NSYSU digits examples](nsysu-digits-examples.png \"NSYSU digits examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 資料來源\n",
    "- 來自學生小考考卷\n",
    "- 課前詢問學生是否同意以匿名方式貢獻資料\n",
    "- 由研究助理加標籤\n",
    "- 公開在 GitHub: [SageLabTW/auto-grading.git](https://github.com/SageLabTW/auto-grading) [ [LICENSE](https://github.com/SageLabTW/auto-grading/blob/master/nsysu-digits/LICENSE) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 資料前處理\n",
    "- 每張圖大小為 28x28\n",
    "- 數字大小不一致\n",
    "- 白 0 ~ 255 黑（顏色偏淺）\n",
    "- 未置中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### MNIST 訓練、NSYSU-digits 測試\n",
    "- random: ~10%\n",
    "- ink: 6%\n",
    "- kNN: 13% (1 minutes)\n",
    "- linear: 21%\n",
    "- SVM: 27% (5 minutes)\n",
    "- NN: 28%\n",
    "- CNN: 44% (one epoch) ~ 58%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Les Misérables](https://upload.wikimedia.org/wikipedia/en/6/67/LesMisLogo.png \"Les Misérables\")\n",
    "\n",
    "(Source: [Wikipedia of Les Misérables (musical)](https://en.wikipedia.org/wiki/Les_Mis%C3%A9rables_(musical)  \n",
    "[Details of copyright](https://en.wikipedia.org/wiki/File:LesMisLogo.png))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " 悲慘世界"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### random guess\n",
    "guess = np.random.randint(0, 10, (num,))\n",
    "accuracy_score(ysys, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### ink density guess\n",
    "centers = np.zeros((10,1))\n",
    "label = np.arange(10)\n",
    "for i in range(10):\n",
    "    mask = (y_train == i)\n",
    "    centers[i,0] = X_train[mask].mean()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(1)\n",
    "model.fit(centers, label)\n",
    "inks = Xsys.mean(axis=1)[:,np.newaxis]\n",
    "guess = model.predict(inks)\n",
    "accuracy_score(ysys, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(Xf_train, y_train)\n",
    "guess = model.predict(Xsys)\n",
    "accuracy_score(ysys, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### linear\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(hidden_layer_sizes=(), activation='identity')\n",
    "model.fit(Xf_train, y_train)\n",
    "guess = model.predict(Xsys)\n",
    "accuracy_score(ysys, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### SVM\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(Xf_train, y_train)\n",
    "guess = model.predict(Xsys)\n",
    "accuracy_score(ysys, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### neural network\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(Xf_train, yone_train, epochs=10, batch_size=100, validation_data=(Xsys, ysysone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### convolution neural network\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), \n",
    "                                 activation='relu', \n",
    "                                 input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(Xcnn_train, yone_train, epochs=1, batch_size=100, validation_data=(Xsyscnn, ysysone))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### NSYSU-digits 3/4 訓練、1/4 測試\n",
    "- random: ~10%\n",
    "- ink: 19%\n",
    "- kNN: 45%\n",
    "- linear: **34%**\n",
    "- SVM: 52%\n",
    "- NN: **25%**\n",
    "- CNN: **32%** (one epoch) ~ 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### split the data\n",
    "Xsys_train, Xsys_test, ysys_train, ysys_test = train_test_split(Xsys, ysys)\n",
    "num_train,num_test =  Xsys_train.shape[0], Xsys_test.shape[0]\n",
    "Xsyscnn_train = Xsys_train.reshape(num_train, 28, 28, 1)\n",
    "Xsyscnn_test = Xsys_test.reshape(num_test, 28, 28, 1)\n",
    "ysysone_train = tf.keras.utils.to_categorical(ysys_train)\n",
    "ysysone_test = tf.keras.utils.to_categorical(ysys_test)\n",
    "print(num_train, num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### random guess\n",
    "guess = np.random.randint(0, 10, (num_test,))\n",
    "accuracy_score(ysys_test, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### ink density guess\n",
    "centers = np.zeros((10,1))\n",
    "label = np.arange(10)\n",
    "for i in range(10):\n",
    "    mask = (ysys_train == i)\n",
    "    centers[i,0] = Xsys_train[mask].mean()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(1)\n",
    "model.fit(centers, label)\n",
    "inks = Xsys_test.mean(axis=1)[:,np.newaxis]\n",
    "guess = model.predict(inks)\n",
    "accuracy_score(ysys_test, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(Xsys_train, ysys_train)\n",
    "guess = model.predict(Xsys_test)\n",
    "accuracy_score(ysys_test, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### linear\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(hidden_layer_sizes=(), activation='identity')\n",
    "model.fit(Xsys_train, ysys_train)\n",
    "guess = model.predict(Xsys_test)\n",
    "accuracy_score(ysys_test, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### SVM\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(Xsys_train, ysys_train)\n",
    "guess = model.predict(Xsys_test)\n",
    "accuracy_score(ysys_test, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### neural network\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(Xsys_train, ysysone_train, epochs=10, batch_size=100, validation_data=(Xsys_test, ysysone_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### convolution neural network\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), \n",
    "                                 activation='relu', \n",
    "                                 input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(Xsyscnn_train, ysysone_train, epochs=20, batch_size=100, validation_data=(Xsyscnn_test, ysysone_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 整體比較（準確率 in %）\n",
    "| | M to M | M to N | N to N |\n",
    "|-------|-------|-------|-------|\n",
    "|random| 10 | 10 | 10 |\n",
    "|ink   | 22 | 6 | 19 |\n",
    "|kNN   | 98.8 | 13 | 45 |\n",
    "|linear| 88 | 21 | 34 |\n",
    "|SVM   | 97 | 27 | 52 |\n",
    "|NN    | 92 | 28 | 25 |\n",
    "|CNN   | 97 | 44 | 32 |\n",
    "\n",
    "M: MNIST  \n",
    "N: NSYSU-digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "資料科學的用意不只在於使用模型  \n",
    "更重要的是**在結果不如預期的時候了解可能的原因**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data processing\n",
    "資料前處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[back to top](#%E6%88%91%E5%80%91%E8%88%87%E6%95%B8%E5%AD%97%E8%BE%A8%E8%AD%98%E7%9A%84%E8%B7%9D%E9%9B%A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**這區的 code 須要[開頭](#%E6%88%91%E5%80%91%E8%88%87%E6%95%B8%E5%AD%97%E8%BE%A8%E8%AD%98%E7%9A%84%E8%B7%9D%E9%9B%A2)的程式碼讀入 MNIST 資料、下載 NSYSU-digits**  \n",
    "**而且會重設 Xsys, ysys 等變數**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### required functions\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def shift_n_scale(arr, shift, scale=1):\n",
    "    p,q = shift\n",
    "    pad = max(abs(p), abs(q))\n",
    "    a,b = arr.shape\n",
    "    new = np.zeros((a + 2*pad, b + 2*pad), dtype=arr.dtype)\n",
    "    new[pad+p:pad+p+a, pad+q:pad+q+b] = scale*arr\n",
    "    return new[pad:pad+a, pad:pad+b]\n",
    "\n",
    "def thicken(arr, rad=2, decay=0.8):\n",
    "    moves = []\n",
    "    for i in range(-rad, rad+1):\n",
    "        for j in range(-rad, rad+1):\n",
    "            dist = abs(i) + abs(j)\n",
    "            if dist <= rad - 1:\n",
    "                moves.append(shift_n_scale(arr, (i,j), scale=decay**dist))\n",
    "    new_arr = np.array(moves)\n",
    "    return new_arr.max(axis=0)\n",
    "\n",
    "def level(arr, thres=10, a=1, b=100):\n",
    "    m,n = arr.shape\n",
    "    new_arr = arr.copy()\n",
    "    new_arr[arr > thres] = new_arr[arr > thres] * a + b\n",
    "    upd = np.zeros_like(arr) + 255\n",
    "    thick = np.concatenate([new_arr[np.newaxis,:,:], upd[np.newaxis,:,:]], axis=0)\n",
    "    return thick.min(axis=0)\n",
    "\n",
    "def bounding_box(arr, thres=10, out='subarray'):\n",
    "    \"\"\"\n",
    "    out can be 'bounds' or 'subarray'\n",
    "    \"\"\"\n",
    "    xs,ys = np.where(arr > 10)\n",
    "    if out == 'bounds':\n",
    "        return xs.min(), xs.max(), ys.min(), ys.max()\n",
    "    if out == 'subarray':\n",
    "        return arr[xs.min():xs.max()+1, ys.min():ys.max()+1]\n",
    "    \n",
    "def out_size(in_size, target=20):\n",
    "    x,y = in_size\n",
    "    big = max(x,y)\n",
    "    ratio = float(target) / big \n",
    "    out_x = target if x == big else int(np.ceil(x*ratio))\n",
    "    out_y = target if y == big else int(np.ceil(y*ratio))\n",
    "    return (out_x, out_y)\n",
    "\n",
    "def arr_centers(arr):\n",
    "    m,n = arr.shape\n",
    "    row_sum = np.sum(arr, axis=1)\n",
    "    v_cen = (row_sum * np.arange(m)).sum() / row_sum.sum()\n",
    "    col_sum = np.sum(arr, axis=0)\n",
    "    h_cen = (col_sum * np.arange(n)).sum() / col_sum.sum()\n",
    "    return (v_cen, h_cen)\n",
    "\n",
    "def centerize(arr, target=20):\n",
    "    m,n = arr.shape\n",
    "    new_arr = np.zeros((m + 2*target, n + 2*target), dtype=arr.dtype)\n",
    "    \n",
    "    img = Image.fromarray(bounding_box(arr).astype('uint8'))\n",
    "    o_size = out_size(img.size, target=target)   \n",
    "    re_arr = np.array(img.resize(o_size), dtype=arr.dtype)\n",
    "    v_cen,h_cen = arr_centers(re_arr)\n",
    "    v = target + int(np.round(0.5*n - v_cen))\n",
    "    h = target + int(np.round(0.5*m - h_cen))\n",
    "    vp = v + re_arr.shape[0]\n",
    "    hp = h + re_arr.shape[1]\n",
    "    \n",
    "    new_arr[v:vp, h:hp] = re_arr\n",
    "    return new_arr[target:target+m, target:target+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### load nsysu\n",
    "\n",
    "raw_Xsys = np.genfromtxt('nsysu-digits-X.csv', dtype=int, delimiter=',') ### flattened already\n",
    "ysys = np.genfromtxt('nsysu-digits-y.csv', dtype=int, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Comparison of two datasets](comparison.png \"Comparison of two datasets\")\n",
    "\n",
    "可能的選項：加粗、加深、大小統一、置中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### some zeros and ones\n",
    "### required for generating pictures\n",
    "\n",
    "Ninds = np.concatenate([np.where(ysys == 0)[0][:6], \n",
    "                np.where(ysys == 1)[0][:6]])\n",
    "Minds = np.concatenate([np.where(y_train == 0)[0][:6], \n",
    "                np.where(y_train == 1)[0][:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### generate comparison.png\n",
    "\n",
    "fig = plt.figure(figsize=(7.2,4.8))\n",
    "back = fig.add_axes([0,0,1,1])\n",
    "back.set_axis_off()\n",
    "back.text(0.3,0.9, 'NSYSU-digits', horizontalalignment='center')\n",
    "back.text(0.7,0.9, 'MNIST', horizontalalignment='center')\n",
    "axs = fig.subplots(4,6)\n",
    "for i in range(4):\n",
    "    for j in range(6):\n",
    "        ax = axs[i,j]\n",
    "        ax.set_axis_off()\n",
    "        if j < 3:\n",
    "            ax.imshow(raw_Xsys[Ninds[3*i+j]].reshape(28,28), cmap='Greys')\n",
    "        else:\n",
    "            ax.imshow(X_train[Minds[3*i+j-3]], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 加粗\n",
    "\n",
    "![Thicken the data](thicken.png \"Thicken the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### for generating thicken.png\n",
    "\n",
    "fig,axs = plt.subplots(3,4,figsize=(8,6))\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        ax = axs[i,j]\n",
    "        ax.set_axis_off()\n",
    "        if j == 0:\n",
    "            ax.imshow(raw_Xsys[Ninds[i]].reshape(28,28), cmap='Greys')\n",
    "            if i == 0:\n",
    "                ax.set_title('rad=1')\n",
    "        elif j == 1:\n",
    "            ax.imshow(thicken(raw_Xsys[Ninds[i]].reshape(28,28), rad=2), cmap='Greys')\n",
    "            if i == 0:\n",
    "                ax.set_title('rad=2')\n",
    "        elif j == 2:\n",
    "            ax.imshow(thicken(raw_Xsys[Ninds[i]].reshape(28,28), rad=3), cmap='Greys')\n",
    "            if i == 0:\n",
    "                ax.set_title('rad=3')\n",
    "        else:\n",
    "            ax.imshow(X_train[Minds[i]], cmap='Greys')\n",
    "            if i == 0:\n",
    "                ax.set_title('MNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "參數：`radius`, `decay`\n",
    "\n",
    "![Thicken illustration](thicken-param.png \"Thicken illustration\")  \n",
    "`decay = 0.8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### for generating thicken-param.png\n",
    "\n",
    "arr = np.zeros((5,5), dtype=float)\n",
    "arr[2][2] = 255\n",
    "\n",
    "fig,axs = plt.subplots(1,3, figsize=(6,2))\n",
    "for i in range(3):\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "    axs[i].set_title('rad=%d'%(i+1))\n",
    "    axs[i].imshow(thicken(arr, rad=i+1, decay=0.6), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 加深\n",
    "\n",
    "![Darken the data](darken.png \"Darken the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### for generating darken.png\n",
    "\n",
    "fig,axs = plt.subplots(3,4,figsize=(8,6))\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        ax = axs[i,j]\n",
    "        ax.set_axis_off()\n",
    "        if j <= 2:\n",
    "            ax.imshow(level(raw_Xsys[Ninds[i]].reshape(28,28), b=50*j), cmap='Greys')\n",
    "            if i == 0:\n",
    "                ax.set_title('b=%d'%(50*j))\n",
    "        else:\n",
    "            ax.imshow(X_train[Minds[i]], cmap='Greys')\n",
    "            if i == 0:\n",
    "                ax.set_title('MNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "參數：`thres`, `ax + b` (leveling function)\n",
    "\n",
    "```python\n",
    "new_arr[arr > thres] = new_arr[arr > thres] * a + b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 大小統一\n",
    "\n",
    "![Resize the data](centerize.png \"Resize the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### for generating resize.png\n",
    "\n",
    "fig,axs = plt.subplots(3,3,figsize=(6,6))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax = axs[i,j]\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if j == 0:\n",
    "            ax.imshow(raw_Xsys[Ninds[i]].reshape(28,28), cmap='Greys')\n",
    "            if i == 0:\n",
    "                ax.set_title('original')\n",
    "        elif j == 1:\n",
    "            ax.imshow(centerize(raw_Xsys[Ninds[i]].reshape(28,28)), cmap='Greys')\n",
    "            if i == 0:\n",
    "                ax.set_title('scaled & centerized')\n",
    "        else:\n",
    "            ax.imshow(X_train[Minds[i]], cmap='Greys')\n",
    "            if i == 0:\n",
    "                ax.set_title('MNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "參數：`thres`, `target` (size of the bounding box)\n",
    "\n",
    "![Threshold illustration](thres.png \"Threshold illustration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### for generating thres.png\n",
    "\n",
    "fig,axs = plt.subplots(3,4,figsize=(8,6))\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        ax = axs[i,j]\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        thres = 10 * j + 10\n",
    "        if j <= 2:\n",
    "            ax.imshow(raw_Xsys[Ninds[i]].reshape(28,28) >= thres, cmap='Greys')\n",
    "            if i == 0:\n",
    "                ax.set_title('thres=%d'%thres)\n",
    "        else:\n",
    "            ax.imshow(X_train[Minds[i]], cmap='Greys')\n",
    "            if i == 0:\n",
    "                ax.set_title('MNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "參數：`thres`, `target` (size of the bounding box)\n",
    "\n",
    "![Resize illustration](resize-param.png \"Resize illustration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### for generating resize-param.png\n",
    "\n",
    "arr = raw_Xsys[Ninds[0]].reshape(28,28)\n",
    "bounds = bounding_box(arr, out='bounds')\n",
    "height,width = bounds[1]-bounds[0], bounds[3]-bounds[2]\n",
    "h_aug,w_aug = (20-height)/2, (20-width)/2\n",
    "\n",
    "plt.imshow(arr, cmap='Greys')\n",
    "in_rec = plt.Rectangle((bounds[2]-1, bounds[0]-1), width+1, height+1, \n",
    "                       edgecolor='red', lw=2, fill=False)\n",
    "out_rec = plt.Rectangle((bounds[2]-1-w_aug, bounds[0]-1-h_aug), 21, 21, \n",
    "                        edgecolor='blue', lw=2, fill=False)\n",
    "ax = plt.gca()\n",
    "ax.add_patch(in_rec)\n",
    "ax.add_patch(out_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 置中\n",
    "\n",
    "![Centerize the data](centerize.png \"Centerize the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "參數：`thres`\n",
    "\n",
    "    [   0    1    2    3    4    5    6    7    8    9   10   11   12   13  (index)\n",
    "    [   0    0    0    0    0    0    0    0  233 1080  550  310  295  240  (column sum)    \n",
    "    \n",
    "       14   15   16   17   18   19   20   21   22   23   24   25   26   27] (index)\n",
    "      289  402  542  119    0    0    0    0    0    0    0    0    0    0] (column sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "arr = raw_Xsys[Ninds[0]].reshape(28,28)\n",
    "col_sum = np.sum(arr, axis=0)\n",
    "print(np.concatenate([np.arange(28)[np.newaxis,:], col_sum[np.newaxis,:]], axis=0))\n",
    "print(\"horizontal mass center at\", (col_sum * np.arange(28)).sum() / col_sum.sum()) # shift to 13.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 加粗、加深、統一大小並置中\n",
    "| | M to N | M to thicken | M to dark | M to center | M to ??? |\n",
    "|-------|-------|-------|-------|-------|-------|\n",
    "|random| 10 | 10 | 10 | 10 | 10 |\n",
    "|ink   | 6 | 9 | 7 | 7 | 12 |\n",
    "|kNN   | 13 | 27 | 26 | 52 | 87 |\n",
    "|linear| 21 | 22 | 25 | 74 | 76 |\n",
    "|SVM   | 27 | 38 | 40 | 75 | 91 |\n",
    "|NN    | 28 | 28 | 29 | 70 | 82 |\n",
    "|CNN   | 44 | 45 | 49 | 90 | 95 |\n",
    "\n",
    "M: MNIST  \n",
    "N: NSYSU-digits  \n",
    "thicken: thicken NSYSU-digits (rad=2, decay=0.8)  \n",
    "dark: darkened NSYSU-digits (+100)  \n",
    "center: centerized NSYSU-digits (fit to 20x20 and centered by mass)  \n",
    "???: some formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "Xsys = np.zeros_like(raw_Xsys)\n",
    "for i in range(raw_Xsys.shape[0]):\n",
    "    arr = raw_Xsys[i].reshape(28,28)\n",
    "    arr = thicken(arr) ### decide whether to thicken\n",
    "#     arr = level(arr) ### decide whether to darken\n",
    "#     arr = centerize(arr) ### decide whether to center\n",
    "    Xsys[i] = arr.reshape(784)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### check your new data\n",
    "\n",
    "fig,axs = plt.subplots(4,3, figsize=(6,8))\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        ax = axs[i,j]\n",
    "        ax.set_axis_off()\n",
    "        if j == 0:\n",
    "            ax.imshow(raw_Xsys[i].reshape(28,28), cmap='Greys')\n",
    "        elif j == 1:\n",
    "            ax.imshow(Xsys[i].reshape(28,28), cmap='Greys')\n",
    "        else:\n",
    "            ax.imshow(X_train[i], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "num = Xsys.shape[0] ### 552\n",
    "Xsyscnn = Xsys.reshape(num, 28, 28, 1)\n",
    "ysysone = tf.keras.utils.to_categorical(ysys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### random guess\n",
    "guess = np.random.randint(0, 10, (num,))\n",
    "accuracy_score(ysys, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### ink density guess\n",
    "centers = np.zeros((10,1))\n",
    "label = np.arange(10)\n",
    "for i in range(10):\n",
    "    mask = (y_train == i)\n",
    "    centers[i,0] = X_train[mask].mean()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(1)\n",
    "model.fit(centers, label)\n",
    "inks = Xsys.mean(axis=1)[:,np.newaxis]\n",
    "guess = model.predict(inks)\n",
    "accuracy_score(ysys, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(Xf_train, y_train)\n",
    "guess = model.predict(Xsys)\n",
    "accuracy_score(ysys, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### linear\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(hidden_layer_sizes=(), activation='identity')\n",
    "model.fit(Xf_train, y_train)\n",
    "guess = model.predict(Xsys)\n",
    "accuracy_score(ysys, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### SVM\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(Xf_train, y_train)\n",
    "guess = model.predict(Xsys)\n",
    "accuracy_score(ysys, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### neural network\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(Xf_train, yone_train, epochs=10, batch_size=100, validation_data=(Xsys, ysysone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "### convolution neural network\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), \n",
    "                                 activation='relu', \n",
    "                                 input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(Xcnn_train, yone_train, epochs=1, batch_size=100, validation_data=(Xsyscnn, ysysone))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 須要處理的變數\n",
    "- `thres`\n",
    "- `ax + b` (leveling function)\n",
    "- `radius`\n",
    "- `decay`\n",
    "- `target` (size of the bounding box) \n",
    "\n",
    "這些參數的設定目前看起來不錯  \n",
    "**適用於所有狀況嗎？**（掃描器、筆...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### for finding bad examples\n",
    "\n",
    "start = 175\n",
    "fig,axs = plt.subplots(5,5, figsize=(10,10))\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        ind = start + 5*i + j\n",
    "        ax = axs[i,j]\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(ind)\n",
    "        ax.imshow(raw_Xsys[ind].reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### for generating \n",
    "### out_box.png, unusual_writing.png, extra_dot.png\n",
    "\n",
    "ob = [72, 94, 179]\n",
    "uw = [3, 54, 104, 147, 125, 166, 155]\n",
    "ed = [22, 49, 131, 64, 140, 131, 176]\n",
    "l = ob\n",
    "n = len(l)\n",
    "\n",
    "fig,axs = plt.subplots(1,n, figsize=(n*1.3,1.3))\n",
    "for j in range(n):\n",
    "    ax = axs[j]\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(raw_Xsys[l[j]].reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 其它問題\n",
    "超出格子、字體歪斜、額外的一點、非預期的答案或空白..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "超出格子  \n",
    "\n",
    "![Out of box](out_box.png \"Out of box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "字體歪斜  \n",
    "\n",
    "![Unusual writing](unusual_writing.png \"Unusual writing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "額外的一點  \n",
    "\n",
    "![Extra dot](extra_dot.png \"Extra dot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "非預期的答案或空白  \n",
    "\n",
    "- 負數\n",
    "- 三位數\n",
    "- 空白"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Difficulties/Mistakes in the NSYSU-digits project\n",
    "專案中遇到的困難、犯過的錯誤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[back to top](#%E6%88%91%E5%80%91%E8%88%87%E6%95%B8%E5%AD%97%E8%BE%A8%E8%AD%98%E7%9A%84%E8%B7%9D%E9%9B%A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### I have a dream — an auto-grading system\n",
    "\n",
    "![](https://media.giphy.com/media/3oriffF0Lt6ioJie08/giphy.gif)\n",
    "\n",
    "(Source [Giphy](https://giphy.com/gifs/season-3-the-simpsons-3x16-3oriffF0Lt6ioJie08))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 小考出題自動化\n",
    "[jephianlin/QuizGenerator.git](https://github.com/jephianlin/QuizGenerator.git) [ [sample](http://www.math.nsysu.edu.tw/~chlin/2020FMath203/SampleQuiz1.pdf) ]\n",
    "\n",
    "![Sample of quiz](quiz_p1.png \"Sample of quiz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "分數採全有全無制、滿分 5 分  \n",
    "小考分數 = 課堂小考、所有補考的平均  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "如果課堂小考 0 分，但想拿 4.5  \n",
    "就要再寫對 9 張小考  \n",
    "**而且在這之中沒有犯錯**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**驗證碼區**位於右下角往左上 (1cm, 1cm) 處  \n",
    "大小為 (2cm, 2cm)\n",
    "\n",
    "![Bottom of a quiz paper](quiz_bottom.png \"Bottom of a quiz paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**QR code 區**位於左下角往右上 (1cm,1cm) 處  \n",
    "大小為 (2cm, 2cm)\n",
    "\n",
    "![Bottom of a quiz paper](quiz_bottom.png \"Bottom of a quiz paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Workflow 1](workflow1.jpg \"Workflow 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2019F ~ 2020S\n",
    "在線性代數課中試行小考系統  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "助教幫我跑程式，發現：\n",
    "- 字體大小不一、不置中、有時候截圖還會截到線\n",
    "- QR code 有時候會讀不到\n",
    "- 預測準確率大約 60%（當時他用 FF design of CNN）\n",
    "\n",
    "C.-C. Jay Kuo, Min Zhang, Siyang Li, Jiali Duan, Yueru Chen  \n",
    "[Interpretable convolutional neural networks via feedforward design](https://www.sciencedirect.com/science/article/abs/pii/S104732031930104X)  \n",
    "Journal of Visual Communication and Image Representation, 60: 346–359, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "我當時相信只要神經網路處理好\n",
    "> 字體大小不一、不置中、有時候截圖還會截到線  \n",
    "\n",
    "都不是問題    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "就這樣擺了一年  \n",
    "整年的考卷其實都是助教人工改的  \n",
    "\n",
    "_有好助教的老師像個寶_  \n",
    "由衷感謝 `<(_ _)>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 機械上的誤差\n",
    "- 印表機\n",
    "- 掃描器\n",
    "- 角度大致沒錯、但位差 ~ 2mm\n",
    "- 每臺掃描器掃出來的深度也不同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 人為的誤差\n",
    "每個人也不一定會寫在中心位置、大小也不同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Auto-boxing by 潘昶余\n",
    "![Auto-boxing](auto-boxing.png \"Auto-boxing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2020 Summer\n",
    "\n",
    "一年後我開始準備下一年的課程  \n",
    "決心要在開學前把 auto-grading 搞定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 尺寸錯誤\n",
    "我一直告訴助教驗證碼和 QR code 的位置應該在 (1cm, 1cm) 的位置\n",
    "\n",
    "![Wrong paper size](badbad_quiz_bottom.png \"Wrong paper size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "LaTeX 產出的檔案預設是 US letter  \n",
    "印表機自動縮放印在 A4 的紙上  \n",
    "\n",
    "![Wrong paper size](bad_quiz_bottom.png \"Wrong paper size\")\n",
    "\n",
    "（更精確來說，每一頁的原始檔我有調成 A4，但合併的時候忘了；所以 A4 紙被嵌在 US letter 裡，又被 A4 紙印出來...）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 程式碼有錯\n",
    "圖檔截取出來以後  \n",
    "我開始用各種模型來做數字辨識  \n",
    "\n",
    "每個模型的**準確率都只有 ~10%!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "匯入資料庫的時候  \n",
    "圖片有重新洗牌一次  \n",
    "\n",
    "程式沒寫好...  \n",
    "圖片和答案分兩次洗牌  \n",
    "\n",
    "**答案跟亂數沒兩樣，得到 10% 天經地義**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### QR code 抓不到\n",
    "- 用 pyzbar 這個套件來讀 QR code  \n",
    "- 常常讀不到\n",
    "- 將圖片對比拉大以後有改進  \n",
    "(let `bright = 255` if `bright > 100`)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### QR code fixer by 潘昶余\n",
    "![QR code fixer](bug4.png \"QR code fixer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "加深、補洞  \n",
    "![Fill gaps in the QR code](bug1.png \"Fill gaps in the QR code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 無法克服的障礙\n",
    "學生的名字或學號  \n",
    "目前還是須要助教輸入 `T_T`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2020F\n",
    "自動閱卷系統  \n",
    "掃描 → QR & 辨識 → email 學生  \n",
    "已經幾乎完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**資料沒清洗的狀況下辨識成功率只有 60%**\n",
    "\n",
    "↪ 為了做這投影片才認真清洗  \n",
    "（但目前還是人工辦識）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**學號還是沒辦法處理**\n",
    "\n",
    "↪ 目前還是人工"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**QR code**\n",
    "\n",
    "↪ 出錯一次，程式除錯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "不斷修正改進中：）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "總結"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[back to top](#%E6%88%91%E5%80%91%E8%88%87%E6%95%B8%E5%AD%97%E8%BE%A8%E8%AD%98%E7%9A%84%E8%B7%9D%E9%9B%A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 關於人工智慧\n",
    "- 資料是否前處理過會大幅影響訓練的成果。\n",
    "- 前處理仍仰賴人為參數調整。\n",
    "- 參數調整取決於設備（掃描器）及資料特性（學生用的筆）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 關於專案\n",
    "- 所學應該用在生活上；如果有什麼想法，就應該去試試看。\n",
    "- 一次完成一件事，才有可能累積更大的成果。\n",
    "- 機器在學習、人類也在學習，任何專案都應該是不斷修正的過程。\n",
    "- 提升準確率很好，但如何處理（無可避免的）判斷錯誤也很重要。\n",
    "- 人工和自動的切換，可增強產品的穩健性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 推薦閱讀\n",
    "- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/) by Michael Nielsen  \n",
    "自製神經網路、universality theorem\n",
    "- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) by Jake VanderPlas  \n",
    "資料處理的詳細介紹（NumPy, pandas, matplotlib）、broadcasting in NumPy、face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Questions\n",
    "1. 用 MNIST 訓練、NSYSU-digits 測試合理嗎？\n",
    "2. 目前的資料經過人工前處理後，可以訓練出 95% 的模型；我可以期待這個模型對下一批學生寫出來的字也有同樣的準確率嗎？\n",
    "3. 如果是你，你會如何將 NSYSU-digits 資料做前處理？有沒有更智慧的方法調整前處理的參數？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
